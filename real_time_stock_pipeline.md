# Real-Time Stock Market Data Pipeline using GCP & Apache Beam

## ğŸ“Œ Project Overview
This project builds a **real-time stock market data pipeline** using **Google Cloud Platform (GCP), Apache Beam, Kafka, and Apache Airflow**. The pipeline streams live stock prices, processes the data, and stores it in **BigQuery** for analysis.

---

## ğŸš€ Tech Stack
- **Google Cloud Platform (GCP)**: BigQuery, Pub/Sub, Cloud Storage, Dataflow, Composer (Airflow)
- **Apache Kafka**: Real-time messaging
- **Apache Beam**: ETL data processing
- **Apache Airflow**: Workflow orchestration
- **Python**: Scripting and data processing
- **Looker Studio**: Visualization & reporting

---

## ğŸ¯ Features
âœ… Real-time stock price ingestion from a simulated stock market feed
âœ… Data validation and transformation using Apache Beam
âœ… Automatic table creation in BigQuery
âœ… Batch and streaming mode support
âœ… Airflow DAG for automated scheduling
âœ… Interactive dashboard using Looker Studio

---

## ğŸ“ Folder Structure
```
ğŸ“‚ real-time-stock-pipeline
â”‚â”€â”€ ğŸ“‚ scripts
â”‚   â”œâ”€â”€ producer.py  # Simulated stock market feed
â”‚   â”œâ”€â”€ consumer.py  # Kafka consumer (optional)
â”‚â”€â”€ ğŸ“‚ apache_beam
â”‚   â”œâ”€â”€ etl_pipeline.py  # Apache Beam ETL pipeline
â”‚â”€â”€ ğŸ“‚ airflow_dags
â”‚   â”œâ”€â”€ stock_data_pipeline.py  # Airflow DAG
â”‚â”€â”€ ğŸ“‚ config
â”‚   â”œâ”€â”€ config.yaml  # GCP and Kafka settings
â”‚â”€â”€ README.md
```

---

## ğŸ› ï¸ Setup & Installation

### ğŸ”¹ Step 1: Clone the Repository
```bash
git clone https://github.com/your-repo/real-time-stock-pipeline.git
cd real-time-stock-pipeline
```

### ğŸ”¹ Step 2: Install Dependencies
```bash
pip install apache-beam[gcp] google-cloud-bigquery google-cloud-pubsub apache-airflow kafka-python
```

### ğŸ”¹ Step 3: Setup Google Cloud Platform (GCP)
- **Enable APIs**: BigQuery, Pub/Sub, Dataflow, Cloud Storage, Cloud Composer
- **Create BigQuery Dataset & Table**:
```sql
CREATE TABLE stock_analysis.stock_prices (
  timestamp TIMESTAMP,
  symbol STRING,
  price FLOAT64,
  volume INT64
);
```
- **Create a Pub/Sub Topic**:
```bash
gcloud pubsub topics create stock-prices
gcloud pubsub subscriptions create stock-sub --topic=stock-prices
```

---

## ğŸ“¡ Data Ingestion with Kafka or Pub/Sub
### ğŸ”¹ Run Kafka Producer (Simulated Stock Data Stream)
```bash
python scripts/producer.py
```
### ğŸ”¹ Run Kafka Consumer (Optional for Debugging)
```bash
python scripts/consumer.py
```

---

## ğŸ”„ Data Processing with Apache Beam (Dataflow)
### ğŸ”¹ Run ETL Pipeline Locally
```bash
python apache_beam/etl_pipeline.py --runner DirectRunner
```
### ğŸ”¹ Deploy to Google Cloud Dataflow
```bash
python apache_beam/etl_pipeline.py --runner DataflowRunner --project your-gcp-project --temp_location gs://your-bucket/temp/
```

---

## ğŸ“… Automate with Apache Airflow (Cloud Composer)
### ğŸ”¹ Upload DAG to Airflow
```bash
cp airflow_dags/stock_data_pipeline.py ~/airflow/dags/
```
### ğŸ”¹ Start Airflow Scheduler
```bash
airflow scheduler &
airflow webserver &
```

---

## ğŸ“Š Analyzing Data in BigQuery
### ğŸ”¹ Query Stock Prices
```sql
SELECT symbol, AVG(price) AS avg_price, MAX(price) AS max_price
FROM stock_analysis.stock_prices
GROUP BY symbol;
```

---

## ğŸ“ˆ Visualizing with Looker Studio
1. Connect **BigQuery** to **Looker Studio**
2. Create **Real-time Stock Price Dashboard**
3. Add **Price Trends, Volume Analysis, Moving Averages**

---

## ğŸ”¥ Next Steps
âœ… Deploy on **GKE (Kubernetes)**
âœ… Implement **ML-based price forecasting**
âœ… Add **real-time alert notifications**



